{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> MACHINE LEARNING - PROJECT </center></h1>\n",
    "<center> \"WHAT ARE THE PEOPLE MORE LIKELY TO SURVIVE TO THE BOOLEAN PANDEMIC?\"</center>\n",
    "\n",
    "Notebook structure:\n",
    "* [1. Sample](#sample)\n",
    "    * [1.1. Import Libraries](#import)\n",
    "    * [1.2. Import Datasets](#import2)\n",
    "* [2. Explore](#explore)\n",
    "    * [2.1. Data Exploration](#dataexplore)\n",
    "    * [2.2. Missing Values Analysis](#miss_values)\n",
    "    * [2.3. Outliers Analysis](#outliers)\n",
    "* [3. Modify](#modify)\n",
    "    * [3.1. Transform and Create variables](#transf_create)\n",
    "    * [3.2. Coherence Checking](#coherence)\n",
    "    * [3.3. Correlation analysis](#corr)\n",
    "    * [3.4. Train Validation Partition](#train_val)\n",
    "    * [3.5. Data Standardization](#datastand)\n",
    "    * [3.6. Feature Selection](#feature)\n",
    "* [4. Model](#model)\n",
    "    * [4.1. K Nearest Neighbors](#knn)\n",
    "    * [4.2. K Nearest Centroid](#knc)\n",
    "    * [4.3. Random Forest](#rf)\n",
    "    * [4.4. Decision Tree](#dt)\n",
    "    * [4.5. Passive Aggressive](#pa)\n",
    "    * [4.6. Multi-Layer Perceptron](#mlp)\n",
    "\n",
    "* [5. Assess](#assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"sample\">\n",
    "    \n",
    "# 1. Sample\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import\">\n",
    "\n",
    "## 1.1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from itertools import combinations_with_replacement\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV, PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import2\">\n",
    "\n",
    "## 1.2. Import Datasets\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data/train.csv')\n",
    "test_df = pd.read_csv(r'Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"explore\">\n",
    "    \n",
    "# 2. Explore\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataexplore\">\n",
    "\n",
    "## 2.1. Data Exploration\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Severity', 'Birthday_year', 'Parents or siblings infected', 'Wife/Husband or children infected', \n",
    "    'Medical_Expenses_Family', 'Deceased']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Deceased'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOTE:` Unbalanced learning, test over/under sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"miss_values\">\n",
    "\n",
    "## 2.2. Missing Values Analysis\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of missing values by variable:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of missing values by variable:\")\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medical Tent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the variable \"Medical Tent\", once it as 702 missing values from a total of 900 (78%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Medical_Tent')\n",
    "test_df = test_df.drop(columns='Medical_Tent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To fill the missing values in the variable \"City\", we decide to use the mode, since there are only to observations missing city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df['City'].fillna(df['City'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Birthday Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what concerns the remaining missing values, all from the variable \"Birthday Year\", we decided to apply the K-Nearest-Neighbor algorithm to fill them. This decision was based in the fact that there are 177 missing values, which we consider too much for apllying a simple input (such as mean or median input), but not that many too remove a variable that we consider that might have some importance in our model. \n",
    "Later, with more knowledge of the dataset we might consider remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "knn_vars = df.drop(['Patient_ID', 'Name', 'City', 'Deceased'], axis = 1)\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "X_filled_knn = imputer.fit_transform(knn_vars)\n",
    "years = np.round(X_filled_knn[:,2])\n",
    "\n",
    "for i in range(len(knn_vars)):\n",
    "    if knn_vars.loc[i,'Birthday_year'] < 1900:\n",
    "        print (years[i])\n",
    "        \n",
    "df['Birthday_year'] = years\n",
    "\n",
    "# Test set\n",
    "knn_vars_test = test_df.drop(['Patient_ID', 'Name', 'City'], axis = 1)\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "Xtest_filled_knn = imputer.fit_transform(knn_vars_test)\n",
    "years_df = np.round(Xtest_filled_knn[:,2])\n",
    "test_df['Birthday_year'] = years_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"outliers\">\n",
    "\n",
    "## 2.3. Outliers Analysis\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, figsize=(10, 5), squeeze=False)    \n",
    "sns.boxplot(df[\"Birthday_year\"], color=\"skyblue\", ax=axes[0, 0])\n",
    "sns.boxplot(df[\"Medical_Expenses_Family\"], color=\"blue\", ax=axes[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "sns.distplot(df[\"Birthday_year\"], color=\"skyblue\", ax=axes[0, 0], kde=False)\n",
    "sns.distplot(df[\"Parents or siblings infected\"], color=\"steelblue\", ax=axes[0, 1], kde=False)\n",
    "sns.distplot(df[\"Medical_Expenses_Family\"], color=\"blue\", ax=axes[1, 0], kde=False)\n",
    "sns.distplot(df[\"Wife/Husband or children infected\"], color=\"c\", ax=axes[1, 1], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlier'] = 0\n",
    "df.loc[df['Medical_Expenses_Family']>13000, 'Outlier']=1\n",
    "df['Outlier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Outlier'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"modify\">\n",
    "\n",
    "# 3. Modify\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"transf_create\">\n",
    "\n",
    "## 3.1. Transform and Create variables\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['City'] == 'Santa Fe', 'Santa Fe'] = 1\n",
    "df.loc[df['City'] != 'Santa Fe', 'Santa Fe'] = 0\n",
    "test_df.loc[test_df['City'] == 'Santa Fe', 'Santa Fe'] = 1\n",
    "test_df.loc[test_df['City'] != 'Santa Fe', 'Santa Fe'] = 0\n",
    "\n",
    "df.loc[df['City'] == 'Taos', 'Taos'] = 1\n",
    "df.loc[df['City'] != 'Taos', 'Taos'] = 0\n",
    "test_df.loc[test_df['City'] == 'Taos', 'Taos'] = 1\n",
    "test_df.loc[test_df['City'] != 'Taos', 'Taos'] = 0\n",
    "\n",
    "df['Age'] = 2020 - df['Birthday_year']\n",
    "test_df['Age'] = 2020 - test_df['Birthday_year']\n",
    "\n",
    "df['Family_cases'] = df['Parents or siblings infected'] + df['Wife/Husband or children infected']\n",
    "test_df['Family_cases'] = test_df['Parents or siblings infected'] + test_df['Wife/Husband or children infected']\n",
    "\n",
    "Family_size = pd.DataFrame(df['Patient_ID'].groupby(df['Family_Case_ID']).count())\n",
    "Family_size = Family_size.rename({'Patient_ID':'Family_size'}, axis='columns') \n",
    "df = df.merge(Family_size, on = ['Family_Case_ID'])\n",
    "\n",
    "Family_size_test = pd.DataFrame(test_df['Patient_ID'].groupby(test_df['Family_Case_ID']).count())\n",
    "Family_size_test = Family_size_test.rename({'Patient_ID':'Family_size'}, axis='columns') \n",
    "test_df = test_df.merge(Family_size_test, on = ['Family_Case_ID'])\n",
    "\n",
    "df['Medical_Expenses_Person'] = df['Medical_Expenses_Family']/df['Family_size']\n",
    "test_df['Medical_Expenses_Person'] = test_df['Medical_Expenses_Family']/test_df['Family_size']\n",
    "\n",
    "df['Parents_infected_bin'] = 0\n",
    "df.loc[df['Parents or siblings infected'] != 0, 'Parents_infected_bin'] = 1\n",
    "test_df['Parents_infected_bin'] = 0\n",
    "test_df.loc[test_df['Parents or siblings infected'] != 0, 'Parents_infected_bin'] = 1\n",
    "\n",
    "df['WifeOrChildren_infected_bin'] = 0\n",
    "df.loc[df['Wife/Husband or children infected'] != 0, 'WifeOrChildren_infected_bin'] = 1\n",
    "test_df['WifeOrChildren_infected_bin'] = 0\n",
    "test_df.loc[test_df['Wife/Husband or children infected'] != 0, 'WifeOrChildren_infected_bin'] = 1\n",
    "\n",
    "df.drop(columns = ['City','Name','Outlier','Family_Case_ID','Birthday_year'], inplace = True)\n",
    "test_df.drop(columns = ['City','Name','Family_Case_ID','Birthday_year'], inplace = True)\n",
    "\n",
    "df.set_index('Patient_ID', inplace = True)\n",
    "test_df.set_index('Patient_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family_cases/family_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"coherence\">\n",
    "\n",
    "## 3.2. Coherence Checking\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['Incoherent'] = 0\n",
    "#Acho que deviamos tirar isto, não faz sentdo considerarmos incoerencias e deixarmos ficar\n",
    "df2.loc[df2['Family_cases'] > df2['Family_size'], 'Incoherent'] = 1\n",
    "df2.loc[(df['Age'] > 120) | (df2['Age'] < 0), 'Incoherent'] = 1\n",
    "df2['Incoherent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"corr\">\n",
    "\n",
    "## 3.3. Correlation Analysis\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar se incluímos a dependente na matriz de correlação\n",
    "plt.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "corr_matrix=df.drop(columns=['Wife/Husband or children infected', 'Parents or siblings infected']).corr(method = 'spearman')\n",
    "mask=np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "sns.heatmap(data=corr_matrix, mask=mask, center=0, annot=True, linewidths=2, cmap='coolwarm')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation analysis and based on a threshold of 0.8 (or -0.8) we can conclude that we should choose between removing the variable \"Family Cases\" or both the variables \"Parents or Siblings Infected\" and \"Wife/Husband or children infected\". Besides that, there are some values that we should pay some attention, specially the ones related with the variable \"Medical_Expenses_Person\", which also seems to be strongly correlated with the \"Medical expenses_family\" (0.75) and the \"Severaty\" (-0.79).\n",
    "\n",
    "In section 3.5., we will procceed to feature selection where we will take into account the values obtained with this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"train_val\">\n",
    "\n",
    "## 3.4. Train Validation Partition\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Severity', 'Age', 'Santa Fe', 'Taos', 'Parents_infected_bin', 'WifeOrChildren_infected_bin',\n",
    "        'Family_cases', 'Family_size', 'Medical_Expenses_Person']]\n",
    "\n",
    "y = df['Deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, \n",
    "                                                    random_state = 15, shuffle = True, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"datastand\">\n",
    "\n",
    "## 3.5. Standardization\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "scaler_X_train = scaler.transform(X_train)\n",
    "scaler_X_train = pd.DataFrame(scaler_X_train, columns = ['Severity', 'Age', 'Santa Fe', 'Taos', \n",
    "                                                         'Parents_infected_bin', 'WifeOrChildren_infected_bin',\n",
    "                                                         'Family_cases', 'Family_size', 'Medical_Expenses_Person'])\n",
    "\n",
    "scaler_X_val = scaler.transform(X_val)\n",
    "scaler_X_val = pd.DataFrame(scaler_X_val, columns = ['Severity', 'Age', 'Santa Fe', 'Taos', \n",
    "                                                         'Parents_infected_bin', 'WifeOrChildren_infected_bin',\n",
    "                                                         'Family_cases', 'Family_size', 'Medical_Expenses_Person'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"feature\">\n",
    "\n",
    "## 3.6. Feature Selection\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"lasso\">\n",
    "\n",
    "### 3.6.1. Lasso Regression\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(scaler_X_train, y_train)\n",
    "coef = pd.Series(reg.coef_, index=scaler_X_train.columns)\n",
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(coef, 'Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ridge\">\n",
    "\n",
    "### 3.6.2. Ridge Regression\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV()\n",
    "ridge.fit(X=scaler_X_train, y=y_train)\n",
    "coef_ridge = pd.Series(ridge.coef_, index=scaler_X_train.columns)\n",
    "print(coef_ridge.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(coef_ridge,'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scaler_X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"rfe\">\n",
    "\n",
    "### 3.6.3. Recursive Feature Elimination (RFE)\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,10)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "\n",
    "    X_train_rfe, X_rfe_val, y_train_rfe, y_rfe_val = train_test_split(scaler_X_train, y_train, test_size = 0.3, \n",
    "                                                                      random_state = 100)\n",
    "    \n",
    "    model_rfe = LogisticRegression()\n",
    "    rfe = RFE(model_rfe,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train_rfe,y_train_rfe)\n",
    "    X_rfe_val = rfe.transform(X_rfe_val)\n",
    "    \n",
    "    model_rfe.fit(X_train_rfe,y_train_rfe)\n",
    "    \n",
    "    score = model_rfe.score(X_rfe_val,y_rfe_val)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "        \n",
    "\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6\n",
    "model_rfe = LogisticRegression()\n",
    "rfe = RFE(estimator = model_rfe, n_features_to_select = N)\n",
    "X_rfe = rfe.fit_transform(X = scaler_X_train, y = y_train) \n",
    "\n",
    "selected_features_rfe = pd.Series(rfe.ranking_, index = scaler_X_train.columns)\n",
    "selected_features_rfe.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = ['Severity', 'Age', 'Santa Fe', 'Taos', \n",
    "             'Parents_infected_bin', 'WifeOrChildren_infected_bin',\n",
    "             'Family_cases', 'Family_size', 'Medical_Expenses_Person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"model\">\n",
    "\n",
    "# 4. Model\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:,Variables]\n",
    "test_df = test_df.loc[:,Variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STD_Method (X, method, scale = (-1,1)):\n",
    "        if method == 'Standard':\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            \n",
    "        elif method == 'Min-Max':\n",
    "            scaler = MinMaxScaler(feature_range = scale).fit(X)\n",
    "        \n",
    "        elif method == 'Robust':\n",
    "            scaler = RobustScaler().fit(X)\n",
    "        \n",
    "        X_std = scaler.transform(X)\n",
    "        return pd.DataFrame(X_std, columns = Variables, index = X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Standard', 'Min-Max' or 'Robust'\n",
    "X = STD_Method(X , 'Standard')\n",
    "test_df = STD_Method(test_df , 'Standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"knn\">\n",
    "\n",
    "## 4.1. K Nearest Neighbors\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "knn_parameters = {'n_neighbors' : (3, 5, 10),\n",
    "                  'metric' : ['euclidean', 'cosine', 'manhattan']}\n",
    "\n",
    "knn_grid = GridSearchCV(estimator=knn_clf, param_grid=knn_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "knn_grid.fit(scaler_X_train, y_train)\n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"knc\">\n",
    "\n",
    "## 4.2. K Nearest Centroid\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_clf = NearestCentroid()\n",
    "\n",
    "knc_parameters = {'metric' : ['euclidean', 'cosine', 'manhattan']}\n",
    "\n",
    "knc_grid = GridSearchCV(estimator=knc_clf, param_grid=knc_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "knc_grid.fit(scaler_X_train, y_train)\n",
    "knc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"rfc\">\n",
    "\n",
    "## 4.3. Random Forest\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "rf_parameters = {\"n_estimators\": np.arange(100, 400, 100),\n",
    "                 \"max_features\": ['sqrt', 'log2', 'auto', None],\n",
    "                 \"criterion\": ['gini', 'entropy'],\n",
    "                 \"warm_start\" : [True, False]}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_clf, param_grid=rf_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"dt\">\n",
    "\n",
    "## 4.4. Decision Tree\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "dt_parameters = {\"max_features\": ['sqrt', 'log2', 'auto', None],\n",
    "                 \"splitter\" : ['best', 'random'],\n",
    "                 \"criterion\": ['gini', 'entropy'],\n",
    "                 \"warm_start\" : [True, False]}\n",
    "\n",
    "dt_grid = GridSearchCV(estimator=dt_clf, param_grid=rf_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"pa\">\n",
    "\n",
    "## 4.5. Passive Aggressive\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_clf = PassiveAggressiveClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "pa_parameters = {\"warm_start\" : [True, False],\n",
    "                 \"early_stopping\" : [True, False],\n",
    "                 \"max_iter\" : (100, 500, 1000)}\n",
    "\n",
    "pa_grid = GridSearchCV(estimator=pa_clf, param_grid=pa_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "pa_grid.fit(scaler_X_train, y_train)\n",
    "pa_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"mlp\">\n",
    "\n",
    "## 4.6. Multi-Layer Perceptron\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 1\n",
    "###### Note: Definir os params para um n limitado de Neurons/ Hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=15, max_iter=600)\n",
    "\n",
    "mlp_parameters = {\n",
    "#    'hidden_layer_sizes': [(50,),(50,50,),(50,50,50)],\n",
    "    'activation': ['identity','logistic','tanh', 'relu'],\n",
    "    'solver': ['lbfgs','sgd', 'adam'],\n",
    "    'alpha':np.logspace(-5, 3, 5),\n",
    "#     'batch_size':(),\n",
    "    'learning_rate_init': list(np.linspace(0.00001,0.1,5)),\n",
    "    'warm_start': [True,False],\n",
    "    'learning_rate': ['constant','invscaling','adaptive'],\n",
    "    'early_stopping' : [True,False]\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(estimator=mlp, param_grid=mlp_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "mlp_grid.fit(scaler_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 2.\n",
    "###### Note: Para os params acima encontrados testar todas as combinações de layers/neurons possiveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_layers(min_neurons,max_neurons,n_layers): \n",
    "    l = []\n",
    "    for i in range(min_neurons,max_neurons):\n",
    "        l.append(i)\n",
    "    layersize = list(combinations_with_replacement(l,n_layers))\n",
    "    \n",
    "# combination_layers(10,50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = 15,max_iter = 600,verbose = 1,activation=,solver=,alpha=,learning_rate_init=,\n",
    "                     warm_start=,)\n",
    "\n",
    "mlp_parameters = {\n",
    "    'hidden_layer_sizes': combination_layers(10,50,2)\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(estimator=mlp, param_grid=mlp_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "mlp_grid.fit(scaler_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"assess\">\n",
    "\n",
    "# 5. Assess\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = knn_grid\n",
    "labels_train = model.predict(scaler_X_train)\n",
    "labels_val = model.predict(scaler_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "    \n",
    "metrics(y_train, labels_train, y_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_param_model\n",
    "version = 1\n",
    "\n",
    "test_output = model.predict(test_data)\n",
    "test_output = pd.DataFrame(test_output, columns = [\"Repeater\"])\n",
    "test_output[\"Patient_ID\"] = test_df.index\n",
    "cols = list(test_output)\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "test_output = test_output[cols]\n",
    "test_output = test_output.sort_values(by=['Patient_ID'])\n",
    "\n",
    "path = '\\\\Data\\\\version' + str(version) + '.csv'\n",
    "test_output.to_csv(path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
