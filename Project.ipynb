{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> MACHINE LEARNING PROJECT </center></h1>\n",
    "<center> \"WHAT ARE THE PEOPLE MORE LIKELY TO SURVIVE TO THE BOOLEAN PANDEMIC?\"</center>\n",
    "\n",
    "Notebook structure:\n",
    "* [1. Sample](#sample)\n",
    "    * [1.1. Import Libraries](#import)\n",
    "    * [1.2. Import Datasets](#import2)\n",
    "* [2. Explore](#explore)\n",
    "    * [2.1. Data Exploration](#dataexplore)\n",
    "    * [2.2. Missing Values Analysis](#miss_values)\n",
    "    * [2.3. Outliers Analysis](#outliers)\n",
    "* [3. Modify](#modify)\n",
    "    * [3.1. Transform and Create variables](#transf_create)\n",
    "    * [3.2. Coherence Checking](#coherence)\n",
    "    * [3.3. Correlation analysis](#corr)\n",
    "    * [3.4. Data Standardization](#datastand)\n",
    "    * [3.5. Feature Selection](#feature)\n",
    "        * [3.5.1. Lasso Regression](#lasso)\n",
    "        * [3.5.2. Ridge Regression](#ridge)\n",
    "        * [3.5.3. Recursive Feature Elimination (RFE)](#rfe)\n",
    "* [4. Model](#model)\n",
    "    * [4.1. K Nearest Neighbors](#knn)\n",
    "    * [4.2. K Nearest Centroid](#knc)\n",
    "    * [4.3. Random Forest](#rf)\n",
    "    * [4.4. Decision Tree](#dt)\n",
    "    * [4.5. Passive Aggressive](#pa)\n",
    "\n",
    "* [5. Assess](#assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"sample\">\n",
    "    \n",
    "# 1. Sample\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import\">\n",
    "\n",
    "## 1.1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer \n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n"
    "from sklearn.linear_model import LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import2\">\n",
    "\n",
    "## 1.2. Import Datasets\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data/train.csv')\n",
    "test_df = pd.read_csv(r'Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"explore\">\n",
    "    \n",
    "# 2. Explore\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataexplore\">\n",
    "\n",
    "## 2.1. Data Exploration\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Deceased'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOTE:` Unbalanced learning, test over/under sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"miss_values\">\n",
    "\n",
    "## 2.2. Missing Values Analysis\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of missing values by variable:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of missing values by variable:\")\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medical Tent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the variable \"Medical Tent\", once it as 702 missing values from a total of 900 (78%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Medical_Tent')\n",
    "test_df = test_df.drop(columns='Medical_Tent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To fill the missing values in the variable \"City\", we decide to use the mode, since there are only to observations missing city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df['City'].fillna(df['City'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Birthday Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what concerns the remaining missing values, all from the variable \"Birthday Year\", we decided to apply the K-Nearest-Neighbor algorithm to fill them. This decision was based in the fact that there are 177 missing values, which we consider too much for apllying a simple input (such as mean or median input), but not that many too remove a variable that we consider that might have some importance in our model. \n",
    "Later, with more knowledge of the dataset we might consider remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "knn_vars = df.drop(['Patient_ID', 'Name', 'City', 'Deceased'], axis = 1)\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "X_filled_knn = imputer.fit_transform(knn_vars)\n",
    "years = np.round(X_filled_knn[:,2])\n",
    "\n",
    "for i in range(len(knn_vars)):\n",
    "    if knn_vars.loc[i,'Birthday_year'] < 1900:\n",
    "        print (years[i])\n",
    "        \n",
    "df['Birthday_year'] = years\n",
    "\n",
    "# For Test\n",
    "knn_vars_test = test_df.drop(['Patient_ID', 'Name', 'City'], axis = 1)\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "Xtest_filled_knn = imputer.fit_transform(knn_vars_test)\n",
    "years_df = np.round(Xtest_filled_knn[:,2])\n",
    "test_df['Birthday_year'] = years_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"outliers\">\n",
    "\n",
    "## 2.3. Outliers Analysis\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, figsize=(10, 5), squeeze=False)    \n",
    "sns.boxplot(df[\"Birthday_year\"], color=\"skyblue\", ax=axes[0, 0])\n",
    "sns.boxplot(df[\"Medical_Expenses_Family\"], color=\"blue\", ax=axes[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "sns.distplot(df[\"Birthday_year\"], color=\"skyblue\", ax=axes[0, 0], kde=False)\n",
    "sns.distplot(df[\"Parents or siblings infected\"], color=\"steelblue\", ax=axes[0, 1], kde=False)\n",
    "sns.distplot(df[\"Medical_Expenses_Family\"], color=\"blue\", ax=axes[1, 0], kde=False)\n",
    "sns.distplot(df[\"Wife/Husband or children infected\"], color=\"c\", ax=axes[1, 1], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlier'] = 0\n",
    "df.loc[df['Medical_Expenses_Family']>13000, 'Outlier']=1\n",
    "df['Outlier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Outlier'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"modify\">\n",
    "\n",
    "# 3. Modify\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"transf_create\">\n",
    "\n",
    "## 3.1. Transform and Create variables\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['City'] == 'Santa Fe', 'Santa Fe'] = 1\n",
    "df.loc[df['City'] != 'Santa Fe', 'Santa Fe'] = 0\n",
    "test_df.loc[test_df['City'] == 'Santa Fe', 'Santa Fe'] = 1\n",
    "test_df.loc[test_df['City'] != 'Santa Fe', 'Santa Fe'] = 0\n",
    "\n",
    "df.loc[df['City'] == 'Albuquerque', 'Albuquerque'] = 1\n",
    "df.loc[df['City'] != 'Albuquerque', 'Albuquerque'] = 0\n",
    "test_df.loc[test_df['City'] == 'Albuquerque', 'Albuquerque'] = 1\n",
    "test_df.loc[test_df['City'] != 'Albuquerque', 'Albuquerque'] = 0\n",
    "\n",
    "df.loc[df['City'] == 'Taos', 'Taos'] = 1\n",
    "df.loc[df['City'] != 'Taos', 'Taos'] = 0\n",
    "test_df.loc[test_df['City'] == 'Taos', 'Taos'] = 1\n",
    "test_df.loc[test_df['City'] != 'Taos', 'Taos'] = 0\n",
    "\n",
    "df['Age'] = 2020 - df['Birthday_year']\n",
    "test_df['Age'] = 2020 - test_df['Birthday_year']\n",
    "\n",
    "df['Family_cases'] = df['Parents or siblings infected'] + df['Wife/Husband or children infected']\n",
    "test_df['Family_cases'] = test_df['Parents or siblings infected'] + test_df['Wife/Husband or children infected']\n",
    "\n",
    "Family_size = pd.DataFrame(df['Patient_ID'].groupby(df['Family_Case_ID']).count())\n",
    "Family_size = Family_size.rename({'Patient_ID':'Family_size'}, axis='columns') \n",
    "df = df.merge(Family_size, on = ['Family_Case_ID'])\n",
    "\n",
    "Family_size_test = pd.DataFrame(test_df['Patient_ID'].groupby(test_df['Family_Case_ID']).count())\n",
    "Family_size_test = Family_size_test.rename({'Patient_ID':'Family_size'}, axis='columns') \n",
    "test_df = test_df.merge(Family_size_test, on = ['Family_Case_ID'])\n",
    "\n",
    "df['Medical_Expenses_Person'] = df['Medical_Expenses_Family']/df['Family_size']\n",
    "test_df['Medical_Expenses_Person'] = test_df['Medical_Expenses_Family']/test_df['Family_size']\n",
    "\n",
    "df.drop(columns = ['City','Name','Outlier','Family_Case_ID','Birthday_year'], inplace = True)\n",
    "df.set_index('Patient_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"coherence\">\n",
    "\n",
    "## 3.2. Coherence Checking\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['Incoherent'] = 0\n",
    "df2.loc[df2['Family_cases'] > df2['Family_size'], 'Incoherent'] = 1\n",
    "df2.loc[(df['Age'] > 120) | (df2['Age'] < 0), 'Incoherent'] = 1\n",
    "df2['Incoherent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"corr\">\n",
    "\n",
    "## 3.3. Correlation Analysis\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "corr_matrix=df.corr(method = 'spearman').round(2)\n",
    "mask=np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "sns.heatmap(data=corr_matrix, mask=mask, center=0, annot=True, linewidths=2, cmap='coolwarm')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"datastand\">\n",
    "\n",
    "## 3.4. Data Standardization\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Severity', 'Age','Santa Fe', 'Albuquerque', 'Taos',\n",
    "       'Parents or siblings infected', 'Wife/Husband or children infected',\n",
    "       'Medical_Expenses_Family', 'Family_cases', 'Family_size', 'Medical_Expenses_Person']]\n",
    "\n",
    "y = df['Deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X = pd.DataFrame(X, columns = ['Severity', 'Age','Santa Fe', 'Albuquerque', 'Taos',\n",
    "       'Parents or siblings infected', 'Wife/Husband or children infected',\n",
    "       'Medical_Expenses_Family', 'Family_cases', 'Family_size', 'Medical_Expenses_Person'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"feature\">\n",
    "\n",
    "## 3.5. Feature Selection\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"lasso\">\n",
    "\n",
    "### 3.5.1. Lasso Regression\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(X, y)\n",
    "coef = pd.Series(reg.coef_, index=X.columns)\n",
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(coef, 'Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"rfe\">\n",
    "\n",
    "### 3.5.3. Recursive Feature Elimination (RFE)\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,22)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    # we are going to see in the next class this \"train_test_split()\"...\n",
    "    X_train_rfe, X_rfe_val, y_train_rfe, y_rfe_val = train_test_split(X,y, test_size = 0.3, random_state = 100)\n",
    "    \n",
    "    model_rfe = LogisticRegression()\n",
    "    rfe = RFE(model_rfe,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train_rfe,y_train_rfe)\n",
    "    X_rfe_val = rfe.transform(X_rfe_val)\n",
    "    model_rfe.fit(X_train_rfe,y_train_rfe)\n",
    "    \n",
    "    score = model_rfe.score(X_rfe_val,y_rfe_val)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"model\">\n",
    "\n",
    "# 4. Model\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = ['Severity', 'Age', 'Santa Fe', 'Taos', 'Parents or siblings infected', \n",
    "             'Wife/Husband or children infected', 'Medical_Expenses_Family', 'Family_size']\n",
    "X = X.loc[:,Variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"knn\">\n",
    "\n",
    "## 4.1. K Nearest Neighbors\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=15)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(random_state=15)\n",
    "\n",
    "knn_parameters = {'n_neighbors' : (3, 5, 10),\n",
    "                  'metric' : ['euclidean', 'cosine', 'manhattan']}\n",
    "\n",
    "knn_grid = GridSearchCV(estimator=knn_clf, param_grid=knn_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "knn_grid.fit(X, y)\n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"knc\">\n",
    "\n",
    "## 4.2. K Nearest Centroid\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_clf = NearestCentroid(random_state=15)\n",
    "\n",
    "knc_parameters = {'metric' : ['euclidean', 'cosine', 'manhattan']}\n",
    "\n",
    "knc_grid = GridSearchCV(estimator=knc_clf, param_grid=knc_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "knc_grid.fit(X, y)\n",
    "knc_grid.best_params_"
    "#### Grid 1\n",
    "###### Note: Definir os params para um n limitado de Neurons/ Hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"rf\">\n",
    "\n",
    "## 4.3. Random Forest\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "rf_parameters = {\"n_estimators\": np.arange(100, 400, 100),\n",
    "                 \"max_features\": ['sqrt', 'log2', 'auto', None],\n",
    "                 \"criterion\": ['gini', 'entropy'],\n",
    "                 \"warm_start\" : [True, False]}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_clf, param_grid=rf_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "rf_grid.fit(X, y)\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_score_"
    "model = MLPClassifier(random_state = 15,max_iter = 600, verbose = 1)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,),(50,50,),(50,50,50)],\n",
    "    'activation': ['identity','logistic','tanh', 'relu'],\n",
    "    'solver': ['lbfgs','sgd', 'adam'],\n",
    "    'alpha':np.logspace(-5, 3, 5),\n",
    "#     'batch_size':(),\n",
    "    'learning_rate_init': list(np.linspace(0.00001,0.1,5)),\n",
    "    'warm_start': [True,False],\n",
    "    'learning_rate': ['constant','invscaling','adaptive'],\n",
    "    'early_stopping' : [True,False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"dt\">\n",
    "\n",
    "## 4.4. Decision Tree\n",
    "    \n",
    "</a>"
    "#### Grid 2.\n",
    "###### Note: Para os params acima encontrados testar todas as combinações de layers/neurons possiveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "dt_parameters = {\"max_features\": ['sqrt', 'log2', 'auto', None],\n",
    "                 \"splitter\" : ['best', 'random'],\n",
    "                 \"criterion\": ['gini', 'entropy'],\n",
    "                 \"warm_start\" : [True, False]}\n",
    "\n",
    "dt_grid = GridSearchCV(estimator=rf_clf, param_grid=rf_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "dt_grid.fit(X, y)\n",
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"pa\">\n",
    "\n",
    "## 4.5. Passive Aggressive\n",
    "    \n",
    "</a>"
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_layers(min_neurons,max_neurons,n_layers): \n",
    "    l = []\n",
    "    for i in range(min_neurons,max_neurons):\n",
    "        l.append(i)\n",
    "    layersize = list(combinations_with_replacement(l,n_layers))\n",
    "    \n",
    "# combination_layers(10,50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_clf = PassiveAggressiveClassifier(class_weight='balanced', random_state=15)\n",
    "\n",
    "pa_parameters = {\"warm_start\" : [True, False],\n",
    "                 \"early_stopping\" : [True, False],\n",
    "                 \"max_iter\" : (100, 500, 1000)}\n",
    "\n",
    "pa_grid = GridSearchCV(estimator=pa_clf, param_grid=pa_parameters, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "pa_grid.fit(X, y)\n",
    "pa_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_grid.best_score_"
    "model = MLPClassifier(random_state = 15,max_iter = 600,verbose = 1,activation=,solver=,alpha=,learning_rate_init=,\n",
    "                     warm_start=,)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': combination_layers(10,50,2)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
